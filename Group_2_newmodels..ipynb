{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c72a47-2da1-49a3-9a09-e98a5a8f854e",
   "metadata": {},
   "source": [
    "# Experiment with four models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0fb05-0159-420f-9f47-9c611b282dcd",
   "metadata": {},
   "source": [
    "###  Read clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8e5e0f-383f-4ccf-9a1b-df59789ea9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communityname</th>\n",
       "      <th>State</th>\n",
       "      <th>countyCode</th>\n",
       "      <th>communityCode</th>\n",
       "      <th>fold</th>\n",
       "      <th>pop</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pctBlack</th>\n",
       "      <th>pctWhite</th>\n",
       "      <th>pctAsian</th>\n",
       "      <th>...</th>\n",
       "      <th>burglaries</th>\n",
       "      <th>burglPerPop</th>\n",
       "      <th>larcenies</th>\n",
       "      <th>larcPerPop</th>\n",
       "      <th>autoTheft</th>\n",
       "      <th>autoTheftPerPop</th>\n",
       "      <th>arsons</th>\n",
       "      <th>arsonsPerPop</th>\n",
       "      <th>violentPerPop</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11980.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>14.1</td>\n",
       "      <td>114.85</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1132.08</td>\n",
       "      <td>16.0</td>\n",
       "      <td>131.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.41</td>\n",
       "      <td>41.02</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1034.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23123.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>242.37</td>\n",
       "      <td>376.0</td>\n",
       "      <td>1598.78</td>\n",
       "      <td>26.0</td>\n",
       "      <td>110.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>127.56</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1780.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29344.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>274.0</td>\n",
       "      <td>758.14</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>4972.19</td>\n",
       "      <td>136.0</td>\n",
       "      <td>376.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>60.87</td>\n",
       "      <td>218.59</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16656.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1301.78</td>\n",
       "      <td>716.0</td>\n",
       "      <td>4142.56</td>\n",
       "      <td>47.0</td>\n",
       "      <td>271.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.08</td>\n",
       "      <td>306.64</td>\n",
       "      <td>4425.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11245.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>728.93</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>8490.87</td>\n",
       "      <td>91.0</td>\n",
       "      <td>728.93</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.05</td>\n",
       "      <td>374.06</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   communityname  State  countyCode  communityCode  fold      pop  perHoush  \\\n",
       "0          149.0   28.0        55.0          509.0   1.0  11980.0      3.10   \n",
       "1         1034.0   35.0        58.0          424.0   1.0  23123.0      2.82   \n",
       "2         1780.0   34.0       114.0          959.0   1.0  29344.0      2.43   \n",
       "3          664.0   31.0        53.0          213.0   1.0  16656.0      2.40   \n",
       "4          140.0   22.0        82.0          471.0   1.0  11245.0      2.76   \n",
       "\n",
       "   pctBlack  pctWhite  pctAsian  ...  burglaries  burglPerPop  larcenies  \\\n",
       "0      1.37     91.78      6.50  ...        14.1       114.85      138.0   \n",
       "1      0.80     95.57      3.44  ...        57.0       242.37      376.0   \n",
       "2      0.74     94.33      3.43  ...       274.0       758.14     1797.0   \n",
       "3      1.70     97.35      0.50  ...       225.0      1301.78      716.0   \n",
       "4      0.53     89.16      1.17  ...        91.0       728.93     1060.0   \n",
       "\n",
       "   larcPerPop  autoTheft  autoTheftPerPop  arsons  arsonsPerPop  \\\n",
       "0     1132.08       16.0           131.26     2.0         16.41   \n",
       "1     1598.78       26.0           110.55     1.0          4.25   \n",
       "2     4972.19      136.0           376.30    22.0         60.87   \n",
       "3     4142.56       47.0           271.93     5.0         21.08   \n",
       "4     8490.87       91.0           728.93     5.0         40.05   \n",
       "\n",
       "   violentPerPop  nonViolPerPop  \n",
       "0          41.02        1394.59  \n",
       "1         127.56        1955.95  \n",
       "2         218.59        6167.51  \n",
       "3         306.64        4425.45  \n",
       "4         374.06        9988.79  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "file_path = 'Group_2_clean_Data..csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d05aea-d8cb-47aa-bbb7-181cd2202423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop</th>\n",
       "      <th>perHoush</th>\n",
       "      <th>pctBlack</th>\n",
       "      <th>pctWhite</th>\n",
       "      <th>pctAsian</th>\n",
       "      <th>pctHisp</th>\n",
       "      <th>pct12-21</th>\n",
       "      <th>pct12-29</th>\n",
       "      <th>pct16-24</th>\n",
       "      <th>pct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>persHomeless</th>\n",
       "      <th>pctForeignBorn</th>\n",
       "      <th>pctBornStateResid</th>\n",
       "      <th>pctSameHouse-5</th>\n",
       "      <th>pctSameCounty-5</th>\n",
       "      <th>pctSameState-5</th>\n",
       "      <th>landArea</th>\n",
       "      <th>popDensity</th>\n",
       "      <th>pctUsePubTrans</th>\n",
       "      <th>pctOfficDrugUnit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11980.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>11.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>53.72</td>\n",
       "      <td>65.29</td>\n",
       "      <td>78.09</td>\n",
       "      <td>89.14</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1845.9</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23123.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.30</td>\n",
       "      <td>77.17</td>\n",
       "      <td>71.27</td>\n",
       "      <td>90.22</td>\n",
       "      <td>96.12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2186.7</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29344.0</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.35</td>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>44.77</td>\n",
       "      <td>36.60</td>\n",
       "      <td>61.26</td>\n",
       "      <td>82.85</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2780.9</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16656.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>97.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.55</td>\n",
       "      <td>25.20</td>\n",
       "      <td>12.19</td>\n",
       "      <td>17.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>88.71</td>\n",
       "      <td>56.70</td>\n",
       "      <td>90.17</td>\n",
       "      <td>96.24</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3217.7</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11245.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>12.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>73.75</td>\n",
       "      <td>42.22</td>\n",
       "      <td>60.34</td>\n",
       "      <td>89.02</td>\n",
       "      <td>11.5</td>\n",
       "      <td>974.2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pop  perHoush  pctBlack  pctWhite  pctAsian  pctHisp  pct12-21  \\\n",
       "0  11980.0      3.10      1.37     91.78      6.50     1.88     12.47   \n",
       "1  23123.0      2.82      0.80     95.57      3.44     0.85     11.01   \n",
       "2  29344.0      2.43      0.74     94.33      3.43     2.35     11.36   \n",
       "3  16656.0      2.40      1.70     97.35      0.50     0.70     12.55   \n",
       "4  11245.0      2.76      0.53     89.16      1.17     0.52     24.46   \n",
       "\n",
       "   pct12-29  pct16-24  pct65up  ...  persHomeless  pctForeignBorn  \\\n",
       "0     21.44     10.93    11.33  ...           0.1           10.66   \n",
       "1     21.30     10.48    17.18  ...           0.0            8.30   \n",
       "2     25.88     11.01    10.28  ...           0.0            5.00   \n",
       "3     25.20     12.19    17.57  ...           0.0            2.04   \n",
       "4     40.53     28.69    12.65  ...           0.0            1.74   \n",
       "\n",
       "   pctBornStateResid  pctSameHouse-5  pctSameCounty-5  pctSameState-5  \\\n",
       "0              53.72           65.29            78.09           89.14   \n",
       "1              77.17           71.27            90.22           96.12   \n",
       "2              44.77           36.60            61.26           82.85   \n",
       "3              88.71           56.70            90.17           96.24   \n",
       "4              73.75           42.22            60.34           89.02   \n",
       "\n",
       "   landArea  popDensity  pctUsePubTrans  pctOfficDrugUnit  \n",
       "0      13.7      1845.9            9.63               0.2  \n",
       "1      10.6      2186.7            3.84               0.0  \n",
       "2      10.6      2780.9            4.37               0.0  \n",
       "3       5.2      3217.7            3.31               0.0  \n",
       "4      11.5       974.2            0.38               0.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `df` is your DataFrame:\n",
    "df_feature = df.iloc[:, 5:-18]  # Select all rows and columns from index 5 to the 18th-to-last\n",
    "df_target = df['burglaries']  # Select the 'violentPerPop' column as the target variable\n",
    "\n",
    "\n",
    "df_feature.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8fd15-b924-4dfb-9293-c230a9cf7657",
   "metadata": {},
   "source": [
    " # 1 Random foreset model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb01e47-063d-4cd4-9cd6-051170d41bf9",
   "metadata": {},
   "source": [
    "###  1.1 without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f083fb2-7e6c-4e9d-ab40-e6c8975e189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics:\n",
      "  - Mean Squared Error: 515588.70\n",
      "  - R-squared: 0.95\n",
      "Testing Set Metrics:\n",
      "  - Mean Squared Error: 232487.27\n",
      "  - R-squared: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Splitting the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "\n",
    "# Calculate metrics for both train and test sets\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"Testing Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"  - R-squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609f722-4cf0-444d-bfee-536125d828ed",
   "metadata": {},
   "source": [
    "### 1.2 select 40 top important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c7d68b-021c-4210-a8e6-22ce015ad8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Top 40 Features:\n",
      "Training Set Metrics:\n",
      "  - Mean Squared Error: 468989.46\n",
      "  - R-squared: 0.96\n",
      "Testing Set Metrics:\n",
      "  - Mean Squared Error: 194441.16\n",
      "  - R-squared: 0.93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Select top 40 features based on importance\n",
    "feature_importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": df_feature.columns,\n",
    "    \"Importance\": feature_importances\n",
    "})\n",
    "sorted_features = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "top_40_features = sorted_features.head(40)\n",
    "\n",
    "# Step 2: Create reduced datasets with the top 40 features\n",
    "X_train_top40 = X_train[top_40_features[\"Feature\"]]\n",
    "X_test_top40 = X_test[top_40_features[\"Feature\"]]\n",
    "\n",
    "# Step 3: Train a new Random Forest model on the reduced dataset\n",
    "rf_model_top40 = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_model_top40.fit(X_train_top40, y_train)\n",
    "\n",
    "# Step 4: Predict on both training and testing sets\n",
    "y_train_pred_top40 = rf_model_top40.predict(X_train_top40)\n",
    "y_test_pred_top40 = rf_model_top40.predict(X_test_top40)\n",
    "\n",
    "# Step 5: Evaluate the model performance\n",
    "train_mse_top40 = mean_squared_error(y_train, y_train_pred_top40)\n",
    "train_r2_top40 = r2_score(y_train, y_train_pred_top40)\n",
    "\n",
    "test_mse_top40 = mean_squared_error(y_test, y_test_pred_top40)\n",
    "test_r2_top40 = r2_score(y_test, y_test_pred_top40)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Using Top 40 Features:\")\n",
    "print(f\"Training Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse_top40:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2_top40:.2f}\")\n",
    "\n",
    "print(f\"Testing Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error: {test_mse_top40:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2_top40:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54fd05-2440-40c6-b23b-496c1f8f09de",
   "metadata": {},
   "source": [
    "### 1.3 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b5733b-9dd4-4206-a420-610b4270df68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Hyperparameters (Top 40 Features): {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Training Set Metrics (Top 40 Features):\n",
      "  - Mean Squared Error: 1177860.33\n",
      "  - R-squared: 0.90\n",
      "Testing Set Metrics (Top 40 Features):\n",
      "  - Mean Squared Error: 224159.18\n",
      "  - R-squared: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Select the top 40 features (assuming you already have 'top_40_features')\n",
    "X_train_top40 = X_train[top_40_features[\"Feature\"]]\n",
    "X_test_top40 = X_test[top_40_features[\"Feature\"]]\n",
    "\n",
    "# Step 2: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [2, 5, 10, 20],       # Maximum depth of the tree\n",
    "    'min_samples_split': [5, 10], # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [2, 5],   # Minimum samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Step 3: Initialize the Random Forest Regressor\n",
    "rf_model_top40 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Step 4: Initialize GridSearchCV\n",
    "grid_search_top40 = GridSearchCV(\n",
    "    estimator=rf_model_top40, \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',  # Negative MSE as scoring metric\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Step 5: Perform grid search to find the best parameters\n",
    "grid_search_top40.fit(X_train_top40, y_train)\n",
    "\n",
    "# Step 6: Retrieve the best model\n",
    "best_rf_model_top40 = grid_search_top40.best_estimator_\n",
    "\n",
    "# Step 7: Predict on the test set\n",
    "y_pred_top40 = best_rf_model_top40.predict(X_test_top40)\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "test_mse_top40 = mean_squared_error(y_test, y_pred_top40)\n",
    "test_r2_top40 = r2_score(y_test, y_pred_top40)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred_top40 = best_rf_model_top40.predict(X_train_top40)\n",
    "\n",
    "# Calculate metrics for both train and test sets\n",
    "train_mse_top40 = mean_squared_error(y_train, y_train_pred_top40)\n",
    "train_r2_top40 = r2_score(y_train, y_train_pred_top40)\n",
    "\n",
    "# Step 9: Print the results\n",
    "print(f\"Best Hyperparameters (Top 40 Features): {grid_search_top40.best_params_}\")\n",
    "print(f\"Training Set Metrics (Top 40 Features):\")\n",
    "print(f\"  - Mean Squared Error: {train_mse_top40:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2_top40:.2f}\")\n",
    "\n",
    "print(f\"Testing Set Metrics (Top 40 Features):\")\n",
    "print(f\"  - Mean Squared Error: {test_mse_top40:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2_top40:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63cbd666-fb74-4dfe-9c30-030fee923dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training Set Metrics:\n",
      "  - Mean Squared Error: 583407.60\n",
      "  - R-squared: 0.95\n",
      "Testing Set Metrics:\n",
      "  - Mean Squared Error: 253211.20\n",
      "  - R-squared: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Splitting the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],            # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 20],           # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],           # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 5],             # Minimum samples required at each leaf node\n",
    "                # Whether to bootstrap samples\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = best_rf_model.predict(X_train)\n",
    "\n",
    "# Calculate metrics for both train and test sets\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Training Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"Testing Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"  - R-squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7cf11-3e70-4cb9-816a-1960cdb51153",
   "metadata": {},
   "source": [
    "# 2. SVR method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a180af-547e-423c-96eb-390b39a9dedc",
   "metadata": {},
   "source": [
    "## 2.1 Without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6e78795-2d4e-49b9-ae12-0e41926a5a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics using Scaled Features and Target without Feature Selection:\n",
      "  - Mean Squared Error: 7671441.42\n",
      "  - R-squared: 0.33\n",
      "\n",
      "Testing Set Metrics using Scaled Features and Target without Feature Selection:\n",
      "  - Mean Squared Error: 281643.38\n",
      "  - R-squared: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split (No Feature Selection)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Feature and Target Scaling\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Step 3: Train the SVR Model\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Step 4: Predict and Evaluate\n",
    "y_train_pred_scaled = svr_model.predict(X_train_scaled)\n",
    "y_pred_scaled = svr_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse-transform predictions and target back to original scale\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for the testing set\n",
    "test_mse = mean_squared_error(y_test_original, y_pred)\n",
    "test_r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Set Metrics using Scaled Features and Target without Feature Selection:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"\\nTesting Set Metrics using Scaled Features and Target without Feature Selection:\")\n",
    "print(f\"  - Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad2b93-6d0e-4d91-ae6c-6dba895ee82f",
   "metadata": {},
   "source": [
    "## 2.2  Applying Lasso feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2fa3b09-d82e-4b49-ad70-77854c0c8807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features by Lasso: ['pop', 'perHoush', 'pctBlack', 'pctWhite', 'pctAsian', 'pctHisp', 'pct12-21', 'pct12-29', 'pct16-24', 'pct65up', 'persUrban', 'pctUrban', 'medIncome', 'pctWwage', 'pctWfarm', 'pctWdiv', 'pctWsocsec', 'pctPubAsst', 'pctRetire', 'medFamIncome', 'perCapInc', 'whitePerCap', 'blackPerCap', 'NAperCap', 'asianPerCap', 'otherPerCap', 'hispPerCap', 'persPoverty', 'pctPoverty', 'pctLowEdu', 'pctNotHSgrad', 'pctCollGrad', 'pctUnemploy', 'pctEmploy', 'pctEmployMfg', 'pctEmployProfServ', 'pctOccupManu', 'pctOccupMgmt', 'pctMaleDivorc', 'pctMaleNevMar', 'pctFemDivorc', 'pctAllDivorc', 'persPerFam', 'pct2Par', 'pctKids2Par', 'pctKids-4w2Par', 'pct12-17w2Par', 'pctWorkMom-6', 'pctWorkMom-18', 'kidsBornNevrMarr', 'pctKidsBornNevrMarr', 'numForeignBorn', 'pctFgnImmig-3', 'pctFgnImmig-5', 'pctFgnImmig-8', 'pctFgnImmig-10', 'pctImmig-3', 'pctImmig-5', 'pctImmig-8', 'pctImmig-10', 'pctSpeakOnlyEng', 'pctNotSpeakEng', 'pctLargHousFam', 'pctLargHous', 'persPerOccupHous', 'persPerOwnOccup', 'persPerRenterOccup', 'pctPersOwnOccup', 'pctPopDenseHous', 'pctSmallHousUnits', 'medNumBedrm', 'houseVacant', 'pctHousOccup', 'pctHousOwnerOccup', 'pctVacantBoarded', 'pctVacant6up', 'medYrHousBuilt', 'pctHousWOphone', 'pctHousWOplumb', 'ownHousLowQ', 'ownHousMed', 'ownHousUperQ', 'ownHousQrange', 'rentLowQ', 'rentMed', 'rentUpperQ', 'rentQrange', 'medGrossRent', 'medRentpctHousInc', 'medOwnCostpct', 'medOwnCostPctWO', 'persEmergShelt', 'persHomeless', 'pctForeignBorn', 'pctBornStateResid', 'pctSameHouse-5', 'pctSameCounty-5', 'pctSameState-5', 'landArea', 'popDensity', 'pctUsePubTrans', 'pctOfficDrugUnit']\n",
      "Training Set Metrics using Lasso-Selected Features and SVR:\n",
      "  - Mean Squared Error: 7671441.42\n",
      "  - R-squared: 0.33\n",
      "\n",
      "Testing Set Metrics using Lasso-Selected Features and SVR:\n",
      "  - Mean Squared Error: 281643.38\n",
      "  - R-squared: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyz20\\miniconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.938e+08, tolerance: 2.023e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split (No Feature Selection)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Lasso for Feature Selection\n",
    "lasso = Lasso(alpha=0.1, random_state=42)  # Adjust alpha as needed\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = X_train.columns[np.abs(lasso.coef_) > 1e-4]\n",
    "print(f\"Selected Features by Lasso: {list(selected_features)}\")\n",
    "\n",
    "# Subset the dataset with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Step 3: Feature and Target Scaling\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler_X.transform(X_test_selected)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Step 4: Train the SVR Model\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "svr_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Step 5: Predict and Evaluate\n",
    "y_train_pred_scaled = svr_model.predict(X_train_scaled)  # Predictions on training data\n",
    "y_pred_scaled = svr_model.predict(X_test_scaled)        # Predictions on testing data\n",
    "\n",
    "# Inverse-transform predictions and target back to original scale\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for the testing set\n",
    "test_mse = mean_squared_error(y_test_original, y_pred)\n",
    "test_r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Set Metrics using Lasso-Selected Features and SVR:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"\\nTesting Set Metrics using Lasso-Selected Features and SVR:\")\n",
    "print(f\"  - Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea022d0-dd0b-49c3-a76c-3e0bd5a44a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9629f408-4338-480b-9ef4-db1f5a2e01ce",
   "metadata": {},
   "source": [
    "## 2.3 hyperparatmer tuning for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d05fdb-baba-43ec-9fa2-bbaf4f87efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyz20\\miniconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.931e+08, tolerance: 2.023e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features by Lasso: ['pop', 'perHoush', 'pctBlack', 'pctWhite', 'pctAsian', 'pctHisp', 'pct12-21', 'pct12-29', 'pct16-24', 'pct65up', 'persUrban', 'pctUrban', 'medIncome', 'pctWwage', 'pctWfarm', 'pctWdiv', 'pctWsocsec', 'pctPubAsst', 'pctRetire', 'medFamIncome', 'perCapInc', 'whitePerCap', 'blackPerCap', 'NAperCap', 'asianPerCap', 'otherPerCap', 'hispPerCap', 'persPoverty', 'pctPoverty', 'pctLowEdu', 'pctNotHSgrad', 'pctCollGrad', 'pctUnemploy', 'pctEmploy', 'pctEmployMfg', 'pctEmployProfServ', 'pctOccupManu', 'pctOccupMgmt', 'pctMaleDivorc', 'pctMaleNevMar', 'pctFemDivorc', 'pctAllDivorc', 'persPerFam', 'pct2Par', 'pctKids2Par', 'pctKids-4w2Par', 'pct12-17w2Par', 'pctWorkMom-6', 'pctWorkMom-18', 'kidsBornNevrMarr', 'pctKidsBornNevrMarr', 'numForeignBorn', 'pctFgnImmig-3', 'pctFgnImmig-5', 'pctFgnImmig-8', 'pctFgnImmig-10', 'pctImmig-3', 'pctImmig-5', 'pctImmig-8', 'pctImmig-10', 'pctSpeakOnlyEng', 'pctNotSpeakEng', 'pctLargHousFam', 'pctLargHous', 'persPerOccupHous', 'persPerOwnOccup', 'persPerRenterOccup', 'pctPersOwnOccup', 'pctPopDenseHous', 'pctSmallHousUnits', 'medNumBedrm', 'houseVacant', 'pctHousOccup', 'pctHousOwnerOccup', 'pctVacantBoarded', 'pctVacant6up', 'medYrHousBuilt', 'pctHousWOphone', 'pctHousWOplumb', 'ownHousLowQ', 'ownHousMed', 'ownHousUperQ', 'ownHousQrange', 'rentLowQ', 'rentMed', 'rentUpperQ', 'rentQrange', 'medGrossRent', 'medRentpctHousInc', 'medOwnCostpct', 'medOwnCostPctWO', 'persEmergShelt', 'persHomeless', 'pctForeignBorn', 'pctBornStateResid', 'pctSameHouse-5', 'pctSameCounty-5', 'pctSameState-5', 'landArea', 'popDensity', 'pctUsePubTrans', 'pctOfficDrugUnit']\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Hyperparameters: {'C': 10, 'epsilon': 0.1, 'kernel': 'rbf'}\n",
      "Training Set Metrics using Lasso-Selected Features and Tuned SVR:\n",
      "  - Mean Squared Error: 2324247.54\n",
      "  - R-squared: 0.80\n",
      "\n",
      "Testing Set Metrics using Lasso-Selected Features and Tuned SVR:\n",
      "  - Mean Squared Error: 312782.60\n",
      "  - R-squared: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Lasso for Feature Selection\n",
    "lasso = Lasso(alpha=0.01, random_state=42)  # Adjust alpha as needed\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = X_train.columns[np.abs(lasso.coef_) > 1e-4]\n",
    "print(f\"Selected Features by Lasso: {list(selected_features)}\")\n",
    "\n",
    "# Subset the dataset with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Step 3: Feature Scaling\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler_X.transform(X_test_selected)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Step 4: Define the parameter grid for SVR\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100],         # Regularization parameter\n",
    "    'epsilon': [0.01, 0.1, 1], # Epsilon in the loss function\n",
    "    'kernel': ['rbf']          # Radial Basis Function kernel\n",
    "}\n",
    "\n",
    "# Step 5: Hyperparameter Tuning using GridSearchCV\n",
    "svr_model = SVR()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svr_model, \n",
    "    param_grid=param_grid, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    cv=5,  # 5-fold cross-validation for efficiency\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Retrieve the best model and parameters\n",
    "best_svr_model = grid_search.best_estimator_\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Step 6: Predict and Evaluate\n",
    "y_train_pred_scaled = best_svr_model.predict(X_train_scaled)  # Predictions on training data\n",
    "y_pred_scaled = best_svr_model.predict(X_test_scaled)        # Predictions on testing data\n",
    "\n",
    "# Inverse-transform predictions and target back to original scale\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for the testing set\n",
    "test_mse = mean_squared_error(y_test_original, y_pred)\n",
    "test_r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Set Metrics using Lasso-Selected Features and Tuned SVR:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"\\nTesting Set Metrics using Lasso-Selected Features and Tuned SVR:\")\n",
    "print(f\"  - Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204990f4-5c71-49fb-856a-32eb45597ed8",
   "metadata": {},
   "source": [
    "## 3 KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ab31e-b1ce-4b88-a8e9-034733172f94",
   "metadata": {},
   "source": [
    "## 3.1 without select feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2288754-cd2e-4db1-b523-0bb71d4833e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor Results without Feature Selection or Hyperparameter Tuning:\n",
      "  - Training Mean Squared Error: 2437784.33\n",
      "  - Training R-squared: 0.79\n",
      "  - Testing Mean Squared Error: 486828.85\n",
      "  - Testing R-squared: 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Feature Scaling\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Inverse-transform the scaled target variables to original scale\n",
    "y_train_original = scaler_y.inverse_transform(y_train_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Step 3: Train KNN Regressor\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5, weights='uniform', metric='euclidean')  # Default parameters\n",
    "knn_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Step 4: Predict and Evaluate\n",
    "y_pred_scaled = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse-transform predictions and target back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate metrics on the original scale\n",
    "test_mse = mean_squared_error(y_test_original, y_pred)\n",
    "test_r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# Predict for training data and calculate training metrics\n",
    "y_train_pred_scaled = knn_model.predict(X_train_scaled)\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate training MSE and R-squared\n",
    "train_mse = mean_squared_error(y_train_original, y_train_pred)\n",
    "train_r2 = r2_score(y_train_original, y_train_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KNN Regressor Results without Feature Selection or Hyperparameter Tuning:\")\n",
    "print(f\"  - Training Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - Training R-squared: {train_r2:.2f}\")\n",
    "print(f\"  - Testing Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - Testing R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6ad39-bb37-4ee6-92a6-11afd2dbc6ed",
   "metadata": {},
   "source": [
    "## 3.2 select feature with lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4336388c-11d7-4aaf-bc07-034c48806ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features by Lasso: ['pop', 'pctBlack', 'pctWhite', 'pctAsian', 'pctHisp', 'pct12-29', 'pct16-24', 'pct65up', 'persUrban', 'pctUrban', 'medIncome', 'pctWfarm', 'pctWdiv', 'pctWsocsec', 'pctPubAsst', 'pctRetire', 'medFamIncome', 'perCapInc', 'whitePerCap', 'blackPerCap', 'NAperCap', 'asianPerCap', 'otherPerCap', 'hispPerCap', 'persPoverty', 'pctPoverty', 'pctLowEdu', 'pctNotHSgrad', 'pctCollGrad', 'pctUnemploy', 'pctEmploy', 'pctEmployMfg', 'pctEmployProfServ', 'pctOccupManu', 'pctOccupMgmt', 'pctMaleDivorc', 'pctMaleNevMar', 'pctFemDivorc', 'pct2Par', 'pctKids-4w2Par', 'pct12-17w2Par', 'pctWorkMom-6', 'pctWorkMom-18', 'kidsBornNevrMarr', 'pctKidsBornNevrMarr', 'numForeignBorn', 'pctFgnImmig-3', 'pctFgnImmig-5', 'pctFgnImmig-8', 'pctFgnImmig-10', 'pctImmig-3', 'pctImmig-5', 'pctImmig-8', 'pctImmig-10', 'pctSpeakOnlyEng', 'pctNotSpeakEng', 'pctLargHousFam', 'pctLargHous', 'persPerOwnOccup', 'pctPersOwnOccup', 'pctPopDenseHous', 'pctSmallHousUnits', 'medNumBedrm', 'houseVacant', 'pctHousOccup', 'pctHousOwnerOccup', 'pctVacantBoarded', 'pctVacant6up', 'medYrHousBuilt', 'pctHousWOphone', 'pctHousWOplumb', 'ownHousLowQ', 'ownHousMed', 'ownHousUperQ', 'ownHousQrange', 'rentLowQ', 'rentMed', 'rentUpperQ', 'rentQrange', 'medGrossRent', 'medRentpctHousInc', 'medOwnCostpct', 'medOwnCostPctWO', 'persEmergShelt', 'persHomeless', 'pctForeignBorn', 'pctBornStateResid', 'pctSameHouse-5', 'pctSameCounty-5', 'pctSameState-5', 'landArea', 'popDensity', 'pctUsePubTrans', 'pctOfficDrugUnit']\n",
      "KNN Regressor Results with Lasso-Selected Features:\n",
      "  - Training Mean Squared Error: 2444938.88\n",
      "  - Training R-squared: 0.79\n",
      "  - Testing Mean Squared Error: 479995.23\n",
      "  - Testing R-squared: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyz20\\miniconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+08, tolerance: 2.023e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Lasso for Feature Selection\n",
    "lasso = Lasso(alpha=1, random_state=42)  # Adjust alpha as needed\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = X_train.columns[np.abs(lasso.coef_) > 1e-4]\n",
    "print(f\"Selected Features by Lasso: {list(selected_features)}\")\n",
    "\n",
    "# Subset the dataset with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Step 3: Feature Scaling\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler_X.transform(X_test_selected)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Step 4: Train KNN Regressor\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5, weights='uniform', metric='euclidean')  # Default parameters\n",
    "knn_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Step 5: Predict and Evaluate\n",
    "# Predict on the test set\n",
    "y_pred_scaled = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse-transform predictions and target back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate test set metrics\n",
    "test_mse = mean_squared_error(y_test_original, y_pred)\n",
    "test_r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# Predict on the training set for training metrics\n",
    "y_train_pred_scaled = knn_model.predict(X_train_scaled)\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_train_original = scaler_y.inverse_transform(y_train_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate training set metrics\n",
    "train_mse = mean_squared_error(y_train_original, y_train_pred)\n",
    "train_r2 = r2_score(y_train_original, y_train_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KNN Regressor Results with Lasso-Selected Features:\")\n",
    "print(f\"  - Training Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - Training R-squared: {train_r2:.2f}\")\n",
    "print(f\"  - Testing Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - Testing R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6b46f-37e9-4834-8f9f-cd7dbd9c99c3",
   "metadata": {},
   "source": [
    "## 3.3  hyperparmeter tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "848d0b71-b271-4b43-970c-e4dd871122c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyz20\\miniconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+08, tolerance: 2.023e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features by Lasso: ['pop', 'pctBlack', 'pctWhite', 'pctAsian', 'pctHisp', 'pct12-29', 'pct16-24', 'pct65up', 'persUrban', 'pctUrban', 'medIncome', 'pctWfarm', 'pctWdiv', 'pctWsocsec', 'pctPubAsst', 'pctRetire', 'medFamIncome', 'perCapInc', 'whitePerCap', 'blackPerCap', 'NAperCap', 'asianPerCap', 'otherPerCap', 'hispPerCap', 'persPoverty', 'pctPoverty', 'pctLowEdu', 'pctNotHSgrad', 'pctCollGrad', 'pctUnemploy', 'pctEmploy', 'pctEmployMfg', 'pctEmployProfServ', 'pctOccupManu', 'pctOccupMgmt', 'pctMaleDivorc', 'pctMaleNevMar', 'pctFemDivorc', 'pct2Par', 'pctKids-4w2Par', 'pct12-17w2Par', 'pctWorkMom-6', 'pctWorkMom-18', 'kidsBornNevrMarr', 'pctKidsBornNevrMarr', 'numForeignBorn', 'pctFgnImmig-3', 'pctFgnImmig-5', 'pctFgnImmig-8', 'pctFgnImmig-10', 'pctImmig-3', 'pctImmig-5', 'pctImmig-8', 'pctImmig-10', 'pctSpeakOnlyEng', 'pctNotSpeakEng', 'pctLargHousFam', 'pctLargHous', 'persPerOwnOccup', 'pctPersOwnOccup', 'pctPopDenseHous', 'pctSmallHousUnits', 'medNumBedrm', 'houseVacant', 'pctHousOccup', 'pctHousOwnerOccup', 'pctVacantBoarded', 'pctVacant6up', 'medYrHousBuilt', 'pctHousWOphone', 'pctHousWOplumb', 'ownHousLowQ', 'ownHousMed', 'ownHousUperQ', 'ownHousQrange', 'rentLowQ', 'rentMed', 'rentUpperQ', 'rentQrange', 'medGrossRent', 'medRentpctHousInc', 'medOwnCostpct', 'medOwnCostPctWO', 'persEmergShelt', 'persHomeless', 'pctForeignBorn', 'pctBornStateResid', 'pctSameHouse-5', 'pctSameCounty-5', 'pctSameState-5', 'landArea', 'popDensity', 'pctUsePubTrans', 'pctOfficDrugUnit']\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Hyperparameters: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "KNN Regressor Results with Lasso-Selected Features and Hyperparameter Tuning (RandomizedSearchCV):\n",
      "  - Training Mean Squared Error: 0.00\n",
      "  - Training R-squared: 1.00\n",
      "  - Testing Mean Squared Error: 454341.28\n",
      "  - Testing R-squared: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Lasso for Feature Selection\n",
    "lasso = Lasso(alpha=1, random_state=42)  # Adjust alpha as needed\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Select features with non-zero coefficients\n",
    "selected_features = X_train.columns[np.abs(lasso.coef_) > 1e-4]\n",
    "print(f\"Selected Features by Lasso: {list(selected_features)}\")\n",
    "\n",
    "# Subset the dataset with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Step 3: Feature Scaling\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler_X.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler_X.transform(X_test_selected)\n",
    "\n",
    "# Scale target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Step 4: Hyperparameter Tuning with RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_neighbors': randint(4, 10),  # Randomly sample number of neighbors between 4 and 10\n",
    "    'weights': ['uniform', 'distance'],  # Weighting method\n",
    "    'metric': ['euclidean', 'manhattan']  # Distance metrics\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=knn_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of parameter combinations to sample\n",
    "    scoring='neg_mean_squared_error',  # Optimize for MSE\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,  # Ensure reproducibility\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Retrieve the best model and parameters\n",
    "best_knn_model = random_search.best_estimator_\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Step 5: Predict and Evaluate\n",
    "# Predict on the test set\n",
    "y_pred_scaled = best_knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse-transform predictions and target back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate test set metrics\n",
    "test_mse = mean_squared_error(y_test_original, y_pred)\n",
    "test_r2 = r2_score(y_test_original, y_pred)\n",
    "\n",
    "# Predict on the training set for training metrics\n",
    "y_train_pred_scaled = best_knn_model.predict(X_train_scaled)\n",
    "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Calculate training set metrics\n",
    "train_mse = mean_squared_error(y_train_original, y_train_pred)\n",
    "train_r2 = r2_score(y_train_original, y_train_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KNN Regressor Results with Lasso-Selected Features and Hyperparameter Tuning (RandomizedSearchCV):\")\n",
    "print(f\"  - Training Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - Training R-squared: {train_r2:.2f}\")\n",
    "print(f\"  - Testing Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - Testing R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0648cb-3a16-43d8-b945-12b7f9592af1",
   "metadata": {},
   "source": [
    "# 4 Decision tree method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173b3cb-69a5-424d-9147-a8041f599eb0",
   "metadata": {},
   "source": [
    "## 4.1  without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07000b81-9514-4698-8b70-cbace9c731d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics using DecisionTreeRegressor:\n",
      "  - Mean Squared Error: 0.00\n",
      "  - R-squared: 1.00\n",
      "\n",
      "Testing Set Metrics using DecisionTreeRegressor:\n",
      "  - Mean Squared Error: 1092504.58\n",
      "  - R-squared: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Train the DecisionTreeRegressor Model\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Predict and Evaluate\n",
    "y_train_pred = tree_model.predict(X_train)  # Predictions on training data\n",
    "y_test_pred = tree_model.predict(X_test)    # Predictions on testing data\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Set Metrics using DecisionTreeRegressor:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"\\nTesting Set Metrics using DecisionTreeRegressor:\")\n",
    "print(f\"  - Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfed8f-3ef6-43ea-b759-ffdc5ae15737",
   "metadata": {},
   "source": [
    "## 4.2 use feature selection selet top 40 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5bb376-c84d-4129-b084-184f123a0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Important Features: ['pctPubAsst', 'persPerFam', 'pctKids2Par', 'medFamIncome', 'pctNotHSgrad', 'perCapInc', 'pctWsocsec', 'pctVacant6up', 'popDensity', 'pctImmig-3', 'pct16-24', 'pctLowEdu', 'pctEmployMfg', 'whitePerCap', 'medRentpctHousInc', 'pctOccupMgmt', 'pctMaleDivorc', 'pctFgnImmig-3', 'persPerOccupHous', 'pctSameHouse-5', 'NAperCap', 'pctMaleNevMar', 'pctHousOwnerOccup', 'pctSameCounty-5', 'pctSmallHousUnits', 'pctWorkMom-6', 'pctFemDivorc', 'pctImmig-5', 'landArea', 'pctPersOwnOccup', 'pctLargHous', 'persHomeless', 'pctUsePubTrans', 'persEmergShelt', 'houseVacant', 'pop', 'kidsBornNevrMarr', 'numForeignBorn', 'persUrban', 'persPoverty']\n",
      "Training Set Metrics using DecisionTreeRegressor with Top 40 Features:\n",
      "  - Mean Squared Error: 0.00\n",
      "  - R-squared: 1.00\n",
      "\n",
      "Testing Set Metrics using DecisionTreeRegressor with Top 40 Features:\n",
      "  - Mean Squared Error: 799246.49\n",
      "  - R-squared: 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Use Random Forest for Feature Importance\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "important_features = X_train.columns[np.argsort(feature_importances)[-40:]]  # Select top 40 features\n",
    "print(f\"Top 40 Important Features: {list(important_features)}\")\n",
    "\n",
    "# Subset the dataset with the top 40 features\n",
    "X_train_selected = X_train[important_features]\n",
    "X_test_selected = X_test[important_features]\n",
    "\n",
    "# Step 3: Train the DecisionTreeRegressor Model\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 4: Predict and Evaluate\n",
    "y_train_pred = tree_model.predict(X_train_selected)  # Predictions on training data\n",
    "y_test_pred = tree_model.predict(X_test_selected)    # Predictions on testing data\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Set Metrics using DecisionTreeRegressor with Top 40 Features:\")\n",
    "print(f\"  - Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - R-squared: {train_r2:.2f}\")\n",
    "\n",
    "print(f\"\\nTesting Set Metrics using DecisionTreeRegressor with Top 40 Features:\")\n",
    "print(f\"  - Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc3e91-6369-486a-a8c7-070f5cbd5470",
   "metadata": {},
   "source": [
    "## 4.3 hyperparameter tuning for decision tree method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af82811e-a738-41a5-8a11-4fa92a7d5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Important Features: ['pctPubAsst', 'persPerFam', 'pctKids2Par', 'medFamIncome', 'pctNotHSgrad', 'perCapInc', 'pctWsocsec', 'pctVacant6up', 'popDensity', 'pctImmig-3', 'pct16-24', 'pctLowEdu', 'pctEmployMfg', 'whitePerCap', 'medRentpctHousInc', 'pctOccupMgmt', 'pctMaleDivorc', 'pctFgnImmig-3', 'persPerOccupHous', 'pctSameHouse-5', 'NAperCap', 'pctMaleNevMar', 'pctHousOwnerOccup', 'pctSameCounty-5', 'pctSmallHousUnits', 'pctWorkMom-6', 'pctFemDivorc', 'pctImmig-5', 'landArea', 'pctPersOwnOccup', 'pctLargHous', 'persHomeless', 'pctUsePubTrans', 'persEmergShelt', 'houseVacant', 'pop', 'kidsBornNevrMarr', 'numForeignBorn', 'persUrban', 'persPoverty']\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None, 'max_depth': 19, 'criterion': 'friedman_mse'}\n",
      "DecisionTreeRegressor Results with Top 40 Features and Hyperparameter Tuning:\n",
      "  - Training Mean Squared Error: 1124797.91\n",
      "  - Training R-squared: 0.90\n",
      "  - Testing Mean Squared Error: 692712.39\n",
      "  - Testing R-squared: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Use Random Forest for Feature Importance\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "important_features = X_train.columns[np.argsort(feature_importances)[-40:]]  # Select top 40 features\n",
    "print(f\"Top 40 Important Features: {list(important_features)}\")\n",
    "\n",
    "# Subset the dataset with the top 40 features\n",
    "X_train_selected = X_train[important_features]\n",
    "X_test_selected = X_test[important_features]\n",
    "\n",
    "# Step 3: Define Hyperparameter Search Space\n",
    "param_distributions = {\n",
    "    'max_depth': [None] + list(np.arange(5, 21)),  # Maximum depth of the tree\n",
    "    'min_samples_split': np.arange(2, 11),  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': np.arange(1, 11),  # Minimum samples required at a leaf node\n",
    "    'max_features': [None, 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'criterion': ['squared_error', 'friedman_mse']  # Splitting criteria\n",
    "}\n",
    "\n",
    "# Step 4: Hyperparameter Tuning with RandomizedSearchCV\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=tree_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # Number of random combinations to sample\n",
    "    scoring='neg_mean_squared_error',  # Optimize for MSE\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    random_state=42,  # Ensure reproducibility\n",
    "    n_jobs=-1  # Use all available processors\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Retrieve the best model and parameters\n",
    "best_tree_model = random_search.best_estimator_\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Step 5: Predict and Evaluate\n",
    "y_train_pred = best_tree_model.predict(X_train_selected)  # Predictions on training data\n",
    "y_test_pred = best_tree_model.predict(X_test_selected)    # Predictions on testing data\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"DecisionTreeRegressor Results with Top 40 Features and Hyperparameter Tuning:\")\n",
    "print(f\"  - Training Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"  - Training R-squared: {train_r2:.2f}\")\n",
    "print(f\"  - Testing Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"  - Testing R-squared: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34516d6e-e836-4858-9eb1-ecf43cd2cb63",
   "metadata": {},
   "source": [
    "## 5 linear regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2b0a30-2630-4f22-9854-5717da39346b",
   "metadata": {},
   "source": [
    "### 5.1 without feature select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6609f477-c162-4b7c-87ff-8f2ef6e5fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics:\n",
      "  - Mean Squared Error (MSE): 330376.16\n",
      "  - R-squared (R²): 0.97\n",
      "\n",
      "Testing Set Metrics:\n",
      "  - Mean Squared Error (MSE): 260139.59\n",
      "  - R-squared (R²): 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Initialize and Train the Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make Predictions on Both Train and Test Sets\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate the Model on Train and Test Sets\n",
    "# Train Set Metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Test Set Metrics\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Step 5: Display the Results\n",
    "print(f\"Training Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error (MSE): {train_mse:.2f}\")\n",
    "print(f\"  - R-squared (R²): {train_r2:.2f}\\n\")\n",
    "\n",
    "print(f\"Testing Set Metrics:\")\n",
    "print(f\"  - Mean Squared Error (MSE): {test_mse:.2f}\")\n",
    "print(f\"  - R-squared (R²): {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b3c662-512c-455b-8a2f-9f280eebe2e2",
   "metadata": {},
   "source": [
    "### 5.2 applying feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18c2aae-f374-4600-ae89-bf07cbe4d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics After Feature Selection:\n",
      "  - Mean Squared Error (MSE): 381464.09\n",
      "  - R-squared (R²): 0.97\n",
      "\n",
      "Testing Set Metrics After Feature Selection:\n",
      "  - Mean Squared Error (MSE): 218079.41\n",
      "  - R-squared (R²): 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_feature, df_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Feature Selection (Top K Features)\n",
    "k = 10  # Number of top features to select\n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Step 3: Initialize and Train the Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 4: Make Predictions on Both Train and Test Sets\n",
    "y_train_pred = linear_model.predict(X_train_selected)\n",
    "y_test_pred = linear_model.predict(X_test_selected)\n",
    "\n",
    "# Step 5: Evaluate the Model on Train and Test Sets\n",
    "# Train Set Metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Test Set Metrics\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Step 6: Display the Results\n",
    "print(f\"Training Set Metrics After Feature Selection:\")\n",
    "print(f\"  - Mean Squared Error (MSE): {train_mse:.2f}\")\n",
    "print(f\"  - R-squared (R²): {train_r2:.2f}\\n\")\n",
    "\n",
    "print(f\"Testing Set Metrics After Feature Selection:\")\n",
    "print(f\"  - Mean Squared Error (MSE): {test_mse:.2f}\")\n",
    "print(f\"  - R-squared (R²): {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18591f14-1aa5-4ee8-83a9-532e59a1b584",
   "metadata": {},
   "source": [
    "### 5.3 hyperparameter tuning for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c0931d-fda9-4d71-89a8-1e0936a92240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 1000}\n",
      "Training Set Metrics After Hyperparameter Tuning:\n",
      "  - Mean Squared Error (MSE): 381601.03\n",
      "  - R-squared (R²): 0.97\n",
      "\n",
      "Testing Set Metrics After Hyperparameter Tuning:\n",
      "  - Mean Squared Error (MSE): 217511.00\n",
      "  - R-squared (R²): 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Define the Ridge Regression Model\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Step 2: Define the Hyperparameter Grid\n",
    "param_grid = {\n",
    "    \"alpha\": [ 100, 1000, 3000,5000],  # Regularization strengths\n",
    "}\n",
    "\n",
    "# Step 3: Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=\"neg_mean_squared_error\",  # Minimize MSE\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Step 4: Fit GridSearchCV on Training Data\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Step 5: Extract the Best Parameters and Train the Final Model\n",
    "best_params = grid_search.best_params_\n",
    "best_ridge_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make Predictions on Train and Test Sets\n",
    "y_train_pred = best_ridge_model.predict(X_train_selected)\n",
    "y_test_pred = best_ridge_model.predict(X_test_selected)\n",
    "\n",
    "# Step 7: Evaluate the Model on Train and Test Sets\n",
    "# Train Set Metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Test Set Metrics\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Display Results\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Training Set Metrics After Hyperparameter Tuning:\")\n",
    "print(f\"  - Mean Squared Error (MSE): {train_mse:.2f}\")\n",
    "print(f\"  - R-squared (R²): {train_r2:.2f}\\n\")\n",
    "\n",
    "print(f\"Testing Set Metrics After Hyperparameter Tuning:\")\n",
    "print(f\"  - Mean Squared Error (MSE): {test_mse:.2f}\")\n",
    "print(f\"  - R-squared (R²): {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7bce80-68f8-4a61-a49a-eb2fc55d0ef5",
   "metadata": {},
   "source": [
    "# 6 visualization of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adfc1541-41cf-4c1e-b0a8-a349e2308358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for visualization (replace with actual values)\n",
    "stages = [\"Without Feature Selection\", \"After Feature Selection (Lasso)\", \"After Hyperparameter Tuning\"]\n",
    "train_mse = [2437784.33, 2444938.88, 0]  # Example values\n",
    "test_mse = [486828.85, 479995.23, 454341.28]\n",
    "train_r2 = [0.79, 0.79, 1.00]  # Example values\n",
    "test_r2 = [0.81, 0.82, 0.83]\n",
    "\n",
    "# Plot settings\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))  # Create two subplots\n",
    "\n",
    "# Bar Plot for MSE\n",
    "x = np.arange(len(stages))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "ax1.bar(x - width/2, train_mse, width, label='Train MSE', color='skyblue')\n",
    "ax1.bar(x + width/2, test_mse, width, label='Test MSE', color='orange')\n",
    "\n",
    "ax1.set_xlabel('Model Stage')\n",
    "ax1.set_ylabel('Mean Squared Error')\n",
    "ax1.set_title('Comparison of MSE for Each Model Stage')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(stages)\n",
    "ax1.legend()\n",
    "\n",
    "# Bar Plot for R-squared\n",
    "ax2.bar(x - width/2, train_r2, width, label='Train R²', color='skyblue')\n",
    "ax2.bar(x + width/2, test_r2, width, label='Test R²', color='orange')\n",
    "\n",
    "ax2.set_xlabel('Model Stage')\n",
    "ax2.set_ylabel('R-squared')\n",
    "ax2.set_title('Comparison of R² for Each Model Stage')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(stages)\n",
    "ax2.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affd3ea-b620-4591-bc29-e82a89b3bee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Environment",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
